%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 2000 - September - 11
\item 
Let $X_1 , X_2 , \ldots, X_n$ be a random sample of size $n$ from a distribution with density \[f ( x ; θ ) = \frac{2x}{\theta^2} , \; 0 <x < \theta, \; \theta >0 \]

\begin{enumerate}[(a)]
\item Write down the likelihood function clearly and hence by drawing a rough sketch of the likelihood function, show that the maximum likelihood estimator of $\theta$ is given by $\hat{\theta} = max{ X_1 , X_2 , \ldots, X_n }$.
\item
Without calculating $E ( \hat{\theta} )$ , explain why $\hat{\theta}$ is a biased estimator of $\theta$.
\end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% 2000 April Q 11
Start by writing down the likelihood function
\[ L(\alpha) = \frac{( \alpha - 1)^n}{\product (1 + x_i )^\alpha}\]

The log-likelihood function is
\[ l(\alpha)  = \log L(\alpha) = n \log(\alpha - 1) - \alpha \sum \log(1 + x_i ).\]

Differentiating gives

\[ \frac{\partial l(\alpha}{ \partial \alpha} = \frac{n}{\alpha -1} - \sum \log(1 + x_i ) \]
It is easy to see that the log-likelihood has only one turning point, so this can be found by equating the derivative to zero. This gives that the maximum likelihood estimate is

\[ \hat{\alpha} = 1 + \frac{n}{ \sum \log(1 + x_i )}\]

The second derivative is
\[ \frac{\partial^2 l(\alpha}{ \partial \alpha^2} = \frac{-n}{(\alpha -1)^2} \]

So an approximate 95\% confidence interval for $\alpha$ is 
\[ \hat{\alpha} \pm  1.96 \frac{\hat{\alpha} - 1}{\sqrt{n}} .\]

\newpage
%%5
\newpage
11 (i) $L(\theta) = 1 2$
2
: 0
0 otherwise
n
i
i i
x
x
% 5 =
% 
% Π < < \theta
% \theta 
% = 2
2
: max( )
0 otherwise
n
i
n i
x
x
%  Π
% \theta > 
% \theta
% 
% ∴ maximum occurs at \hat{\theta}= max(Xi)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Page 6
(ii) Since $X_i < \theta$ for all i
then $max(Xi) < \theta$ always
∴ $E( \hat{\theta}) < \theta$ ∴$\hat{\theta}$ is biased
Q11 Comment: Few candidates appreciated the significance of the fact that the range of the variable included the unknown parameter $\theta$ and therefore the likelihood $L(\theta)$ has a discontinuity (above which it is decreasing).
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




\newpage

\large 

A market research company intends to estimate the proportion of the population, $\theta$, who support a certain political party. They intend to poll a sample large enough so that a 95\% confidence interval for $\theta$ has a width of 0.03 or less. It is thought that $\theta$ is approximately equal to 0.4.
Assuming that everyone questioned will respond to the poll, calculate the minimum size of sample which the company should take. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%55
\newpage
12 Assuming n will be large enough to make a normal approximation to the
binomial acceptable, the confidence interval will be
% ˆ(1 ˆ ) ˆ 1.96 ,
% n
% \theta - \theta \theta ± where ˆ\theta

\[ \hat{\theta} \pm 1.96  \sqrt{ \frac{\hat{\theta}(1-\hat{\theta})}{n} } \]
 

is the proportion of the sample who support the party.
\begin{itemize}
\item Although $\hat{\theta}$ is unknown, it can be estimated as 0.4, so the width of the interval will be approximately

\[ 2 \times 1.96  \sqrt{ \frac{0.4 \times 0.6 }{n} } \;=\; \frac{1.9204}{\sqrt{n}}\]


\item If this is to be less than 0.03 we must have that
\[ n > \left(  \frac{1.9204}{0.03}   right)^2  = 4097.7\]
We need to take n = 4,098.
\item As n is large, this confirms that we were correct in assuming that a normal
approximation would be appropriate.
\item Notes: As this answer is approximate, approximations (such as replacing 1.96
with 2) are acceptable, as is rounding the final answer.
\item An acceptable alternative would be to estimate $\hat{\theta}$ by 0.415 rather than 0.4; this
is the upper limit of a 95\% confidence interval for $\theta$. This leads to a value of
n = 4,145.
\end{itemize}

\end{document}
